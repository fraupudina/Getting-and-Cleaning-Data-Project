select(cran,country:r_arch)
cran
select(cran, -time)
-5:20
[-5:20]
{-5:20}
(-5:20)
-(5:20)
select -(cran, x:size)
select (cran, x:size)
select (cran, -(x:size))
-(x/;size)
-(x,size)
-(x:size)
select(cran)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version < "3.1.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size < 100500 , r_os== "linux-gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(c(3, 5, NA, 10)))
filter(cran, !is.na(r_version)
filter(cran, (!is.na(r_version))
filter(cran, !is.na"r_version")
filter(cran, !is.na("r_version"))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version) ,ip_id)
cran3 <- select (cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10)
correct_size(cran3)
correct_size <- select(cran3, correct size)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10, correct_size)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb/2^10, correct_size= size_mb+1000)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <-tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
by_package <- group_by(cran)
by_package <- group_by(cran, package)
by_package
mean(size)
summarize(cran)
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, court >679)
top_counts <- filter(pack_sum, count >679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, count)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique,
| probs = 0.99)
quantile(pack_sum$unique,probs = 0.99)
top_unique <- filter (pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
bubmit()
submit()
submit()
submit()
View(result3)
cran
print
cran %>%
select(ip_id, country,package,size) %>%
print
submit()
submit()
submit()
submit()
submit()
# Use filter() to select all rows for which size_mb is
# less than or equal to (<=) 0.5.
#
# If you want your results printed to the console, add
# print to the end of your chain.
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20)
filter(cran, size <= 0.5)%>%
print
submit()
cran
dat
submit()
reset()
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20)
cran %>%
select(ip_id, country, package, size) %>%
mutate(size_mb = size / 2^20) %>%
filter(size_mb <= 0.5) # Your call to filter() goes here
print
?filter
submit()
submit()
skip()
skip()
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package(cran, package)
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter (pack_sum, count > 679)
top_counts
View(top_counts)
top_count_sorted <- arrange(top_counts, desc(count))
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique,probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange (top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
reset()
submit()
submit()
submit()
reset()
submit()
submit()
library(swirl)
rm(list=ls())
swirl()
dwirl()
swirl()
library(tidyr)
students
?gather
gather(student,sex,count,!grade)
gather(student,sex,count,!grade,na.rm=FALSE, Convert = FALSE)
gather(student,sex)
students
gather(students,sex,count,-grade)
students2
gather(students2,sex_class,count)
res <-gather(students2, sex_class, count, -grade)
res
?separate
separate(res,sex_class, c("sex","class"))
submit()
students3
submit()
?spread
submit()
submit()
submit
submit()
submit()
submit()
skip
skip()
extract_numeric("class5")
?mutate
?mutate
submit()
submit()
submit()
submit()
extract_numeric(class1:class5
extract_numeric(class1:class5)
extract_numeric(class1)
extract_numeric("class1:class5")
submit
submit()
extract_numeric("class1","class5")
extract_numeric(["class1":"class5"])
extract_numeric["class1":"class5"]
extract_numeric("class1":"class5")
extract_numeric("class1":"class5")
extract_numeric("class1:class5")
extract_numeric("class1")
extract_numeric("class1:class2")
extract_numeric("class1:&& class2")
submit()
submit()
skip()
students 4
students4
submit()
submit()
submit()
submit()
submit()
passed
failed
mutate(passed, status = "passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows (passed,failed)
sat
submit()
gather(part_sex, count, -score_range)
submit
submit()
sat %>%
select(-contains(total)) %>%
print
sat %>%
select(-contains(total)) %>%
print
sat %>%
select(-contains("total"")) %>%
print
sat %>%
select(-contains("total")) %>%
print
sat %>%
select(-contains("total")) %>%
print
submit()
sat %>%
select(-contains("total")) %>%
separate(part,sex)> %>%
print
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
print
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex,"part","sex")> %>%
print
sat %>%
select(-contains("total")) %>%
gather(part_sex, count, -score_range) %>%
separate(part_sex,into = c("part","sex")> %>%
print
submit()
submit()
submit()
submit()
submit()
submit()
submit
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students,sex,count -grade)
gather(students,sex,count, -grade)
students2
res <- gather(students2,sex_class,count)
res <- gather(students2,sex_class,count, -grade)
res
?separate
separate(sex_class, into = c("sex","class"),sep = "\\_")
separate(students2,sex_class, into = c("sex","class"),sep = "\\_")
separate(students2, sex_class, into = c("sex","class"),sep = "\\_")
separate(res, sex_class, into = c("sex","class"),sep = "\\_")
separate(res, sex_class, c("sex","class"))
submit()
students3
submit()
?spread
submit()
extract_numeric("class5")
submit()
students4
submit()
submit()
submit()
passed
failed
mutate(passed,status="passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows(passed,failed)
sat
sat
submit()
submit()
ype Sys.getlocale("LC_TIME")
Sys.getlocale("LC_TIME")
bye
0
exit
exit()
bye()
swirl()
Sys.getlocale("LC_TIME")
bye()
library(swirl)
ls()
rm(list=ls())
swirl()
library(lubridate)
help(package = lubridate)
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <-now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 197")
mdy("March 12, 197")
mdy("March 12, 1975")
dmy(25081985)
ymd(192012)
ymd("192012")
ymd("19-2-012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 55)
this_moment
?now
now(tzone="America/New_York")
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- nyc + hours(15) + mminutes(50)
arrive <- nyc + hours(15) + minutes(50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- (arrive, tzone="Asia/Hong_Kong")
arrive <- with_tz(arrive, tzone="Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tzone ="Singapore")
last_time <- mdy("June 17, 2008", tz ="Singapore")
last_time
?new_interval
how_long <-new_interval(last_time,arrive, tz=(last_time,"Singapore"))
how_long <-new_interval(last_time,arrive, tz="Singapore")
how_long <-new_interval(last_time,arrive)
as.period(how_long
)
stopwatch()
# Data URL: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
# Project instructions:
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive variable names.
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
# Part 1. Merges the training and the test sets || rbind
# A. Merges the train & test data (X_train : X_test)
dat1 <- read.table("train/X_train.txt")
dat2 <- read.table("test/X_test.txt")
X <- rbind(dat1, dat2)
# B. Merges the train & test data (Y_train : Y_test)
dat1 <- read.table("train/y_train.txt")
dat2 <- read.table("test/y_test.txt")
Y <- rbind(dat1, dat2)
# C. Merges the train & test data (subject_train : subject_test)
dat1 <- read.table("train/subject_train.txt")
dat2 <- read.table("test/subject_test.txt")
S <- rbind(dat1, dat2)
# Part 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# Read and select mean & std deviation from features.txt file
features <- read.table("features.txt")
good_data <- grep("-mean\\(\\)|-std\\(\\)", features[, 2]) # search matches for mean & std deviation : eliminate data that does not match with mean or std deviation
X <- X[, good_data]
names(X) <- features[good_data, 2]
names(X) <- gsub("\\(|\\)", "", names(X)) # replace \\ with ""
names(X) <- tolower(names(X)) # translate names(x) to lowercase
# 3. Uses descriptive activity names to name the activities in the data set.
# Read activity_labels,text file.
activities <- read.table("activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2]))) # replace _ with "" & set activities character to lowercase
Y[,1] = activities[Y[,1], 2]
names(Y) <- "activity"
# 4. Appropriately labels the data set with descriptive activity names.
names(S) <- "subject"
cleaned <- cbind(S, Y, X)
write.table(cleaned, "merged_mean_stddeviation.txt") # 1st set of dataset|| Merged, mean and std deviation
# 5. Creates a 2nd, independent tidy data set with the average of each variable for each activity and each subject.
# Variable declarations
uniq_sub = unique(S)[,1] # Return unique data on Subjects || eliminate duplicates
total_sub = length(unique(S)[,1]) # Return no of subjects
total_xtvt = length(activities[,1]) # Return no of activities
numCols = dim(cleaned)[2] # Specify dimension of leaned dataset to 2
result = cleaned[1:(total_sub*total_xtvt), ]
row = 1
for (s in 1:total_sub) {
for (a in 1:total_xtvt) {
result[row, 1] = uniq_sub[s]
result[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
result[row, 3:numCols] <- colMeans(tmp[, 3:numCols])
row = row+1
}
}
write.table(result, "averageofeach_variable_activities_subject.txt")
setwd("C:/Users/user/Desktop/UCI HAR Dataset")
# Data URL: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
# Project instructions:
# 1. Merges the training and the test sets to create one data set.
# 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# 3. Uses descriptive activity names to name the activities in the data set
# 4. Appropriately labels the data set with descriptive variable names.
# 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject
# Part 1. Merges the training and the test sets || rbind
# A. Merges the train & test data (X_train : X_test)
dat1 <- read.table("train/X_train.txt")
dat2 <- read.table("test/X_test.txt")
X <- rbind(dat1, dat2)
# B. Merges the train & test data (Y_train : Y_test)
dat1 <- read.table("train/y_train.txt")
dat2 <- read.table("test/y_test.txt")
Y <- rbind(dat1, dat2)
# C. Merges the train & test data (subject_train : subject_test)
dat1 <- read.table("train/subject_train.txt")
dat2 <- read.table("test/subject_test.txt")
S <- rbind(dat1, dat2)
# Part 2. Extracts only the measurements on the mean and standard deviation for each measurement.
# Read and select mean & std deviation from features.txt file
features <- read.table("features.txt")
good_data <- grep("-mean\\(\\)|-std\\(\\)", features[, 2]) # search matches for mean & std deviation : eliminate data that does not match with mean or std deviation
X <- X[, good_data]
names(X) <- features[good_data, 2]
names(X) <- gsub("\\(|\\)", "", names(X)) # replace \\ with ""
names(X) <- tolower(names(X)) # translate names(x) to lowercase
# 3. Uses descriptive activity names to name the activities in the data set.
# Read activity_labels,text file.
activities <- read.table("activity_labels.txt")
activities[, 2] = gsub("_", "", tolower(as.character(activities[, 2]))) # replace _ with "" & set activities character to lowercase
Y[,1] = activities[Y[,1], 2]
names(Y) <- "activity"
# 4. Appropriately labels the data set with descriptive activity names.
names(S) <- "subject"
cleaned <- cbind(S, Y, X)
write.table(cleaned, "merged_mean_stddeviation.txt") # 1st set of dataset|| Merged, mean and std deviation
# 5. Creates a 2nd, independent tidy data set with the average of each variable for each activity and each subject.
# Variable declarations
uniq_sub = unique(S)[,1] # Return unique data on Subjects || eliminate duplicates
total_sub = length(unique(S)[,1]) # Return no of subjects
total_xtvt = length(activities[,1]) # Return no of activities
numCols = dim(cleaned)[2] # Specify dimension of leaned dataset to 2
result = cleaned[1:(total_sub*total_xtvt), ]
row = 1
for (s in 1:total_sub) {
for (a in 1:total_xtvt) {
result[row, 1] = uniq_sub[s]
result[row, 2] = activities[a, 2]
tmp <- cleaned[cleaned$subject==s & cleaned$activity==activities[a, 2], ]
result[row, 3:numCols] <- colMeans(tmp[, 3:numCols])
row = row+1
}
}
write.table(result, "averageofeach_variable_activities_subject.txt")
View(cleaned)
View(cleaned)
View(tmp)
View(tmp)
View(features)
View(features)
View(result)
View(result)
View(dat1)
View(dat2)
View(activities)
View(cleaned)
View(S)
View(X)
View(Y)
View(activities)
